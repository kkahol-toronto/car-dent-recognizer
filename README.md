# NeuroEYE Portal â€” Car Damage Analysis

A full-stack application that uses YOLO-based car part detection combined with Azure OpenAI vision analysis to generate detailed insurance-style damage reports.

## Overview

1. **Part Detection** â€” YOLOv8 model detects car parts (bumpers, doors, hood, etc.) in images
2. **Damage Analysis** â€” Azure OpenAI GPT-4 Vision analyzes the image and detected parts to produce a comprehensive damage report
3. **PDF Export** â€” Generate downloadable PDF reports with images and findings table

## Features

- ğŸš— **Part Detection** â€” Detect 21 car part classes with color-coded bounding boxes
- ğŸ” **Damage Analysis** â€” AI-powered assessment using Azure OpenAI GPT-4 Vision
- ğŸ’¬ **Chat with Report** â€” Ask follow-up questions with formatted markdown responses
- ğŸ“„ **PDF Export** â€” Download detailed reports with images and bordered tables
- âœ¨ **Modern UI** â€” Glassmorphic design with sparkle animations during inference
- ğŸ–¼ï¸ **Image Carousel** â€” Easy navigation through dataset images

## Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Select Imageâ”‚â”€â”€â”€â–¶â”‚ Run Prediction   â”‚â”€â”€â”€â–¶â”‚ Detect Parts    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ (YOLO Model)     â”‚    â”‚ (21 classes)    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Chat with Report â”‚â—€â”€â”€â”€â”‚ Damage Analysis â”‚
                   â”‚ (Ask questions)  â”‚    â”‚ (GPT-4 Vision)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚ Download PDF    â”‚
                                           â”‚ (Full report)   â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
â”œâ”€â”€ backend/           # FastAPI server
â”‚   â”œâ”€â”€ main.py        # API endpoints
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env           # Azure OpenAI credentials (create this)
â”œâ”€â”€ frontend/          # Next.js React app
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ page.js    # Main UI component
â”‚       â””â”€â”€ globals.css
â”œâ”€â”€ models/            # Trained YOLO models
â”‚   â””â”€â”€ parts_best.pt  # Car parts detection model
â”œâ”€â”€ scripts/           # Dataset preparation scripts
â”‚   â”œâ”€â”€ prepare_yolo.py
â”‚   â””â”€â”€ prepare_damage_seg.py
â””â”€â”€ data/              # Dataset (not included, add manually)
```

## Quick Start

### 1. Backend Setup

```bash
cd backend
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Create `backend/.env`:
```
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=your-api-key
AZURE_OPENAI_DEPLOYMENT=gpt-4-vision
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

Start the server:
```bash
uvicorn main:app --host 0.0.0.0 --port 8009
```

### 2. Frontend Setup

```bash
cd frontend
npm install
npm run dev -- --port 3009
```

### 3. Add Data

Place the "Car parts and car damages" dataset under `data/`:
```
data/
â”œâ”€â”€ Car damages dataset/
â”‚   â””â”€â”€ File1/
â”‚       â”œâ”€â”€ img/       # Images
â”‚       â””â”€â”€ ann/       # Annotations
â””â”€â”€ Car parts dataset/
    â””â”€â”€ File1/
        â””â”€â”€ ...
```

### 4. Use the App

1. Open http://localhost:3009
2. Browse images with the carousel
3. Click **Run Prediction** to detect car parts
4. Click **Run Damage Analysis** for AI-powered damage assessment
5. View the report modal and download as PDF
6. Use the **Chat with Report** section to ask follow-up questions

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/images` | GET | List available images |
| `/images/{filename}` | GET | Serve image file |
| `/predict` | POST | Run YOLO part detection |
| `/damage-analysis` | POST | Run Azure OpenAI damage analysis |
| `/chat` | POST | Chat with the damage report |
| `/health` | GET | Health check |

## Training Your Own Model

### Prepare Dataset
```bash
pip install -r requirements.txt
python scripts/prepare_yolo.py
```

### Train
```bash
yolo detect train \
  data=yolo_dataset/data.yaml \
  model=yolov8n.pt \
  epochs=300 \
  imgsz=640 \
  device=0
```

Copy the best weights to `models/parts_best.pt`.

## Tech Stack

- **Backend**: FastAPI, Ultralytics YOLO, Azure OpenAI
- **Frontend**: Next.js 14, React, jsPDF
- **ML**: YOLOv8 for object detection

## License

MIT
